{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b43f8dd4-9a4f-463d-91c3-898b68b4f08a",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5c52e26-1f28-445a-b0e0-899c24b31bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84f8a415-0440-4309-ac29-d189df6dbfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1166d534-2f90-4fd2-9874-93683336e170",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43473262-0de1-4b4f-ad1a-f061369c5427",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"bhatthars/nbme_patient_notes\",split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df1f73e4-ae13-47d1-afeb-18fa3ced8cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset = dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = split_dataset['train']\n",
    "eval_dataset = split_dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ba15f6-3f43-41c7-a7ac-ef9fee82417c",
   "metadata": {},
   "source": [
    "# Load base model and tokenizer using 4-bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd2c2629-c15b-436b-acb7-ce70eb6029a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = 'meta-llama/Llama-2-7b-chat-hf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acc080a8-2aa5-47e3-a619-7df7b9588a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "980e8f64-d16d-45a1-96d6-7bc7cfd649d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b443a24ba344759859c568926e56d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=quant_config,\n",
    "    device_map={\"\": 0},use_auth_token='auth_token'\n",
    "    \n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9930a8d6-3bb4-4a8d-ae25-25a8d4e0be8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True,token=\"auth_token\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f863beb3-344d-4d9d-9791-0527449869ca",
   "metadata": {},
   "source": [
    "# Define PEFT QLoRA arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd0131fa-53f0-4398-a770-174b3bed77a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_params = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9151ef4f-1d33-4474-9331-db6d2d32098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=25,\n",
    "    logging_steps=25,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    report_to=\"tensorboard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd73062-7e60-4e9f-9024-0607d37276aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset = eval_dataset,\n",
    "    peft_config=peft_params,\n",
    "    dataset_text_field=\"Prompt\",\n",
    "    max_seq_length=None,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_params,\n",
    "    packing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f57eeb-6406-450a-a189-ed3a01b5d073",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81a58b86-da2f-4b99-bc5c-9423b11203db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 09:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.351700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.708800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.528400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.490600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.420900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.425000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.362900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.410400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=1.5873416137695313, metrics={'train_runtime': 550.6409, 'train_samples_per_second': 1.453, 'train_steps_per_second': 0.363, 'total_flos': 1.2677846263922688e+16, 'train_loss': 1.5873416137695313, 'epoch': 1.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c34e1b-0799-4f4d-afc7-0206fff96940",
   "metadata": {},
   "source": [
    "# Save and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6f3ea63-d41d-468f-8855-c008647212dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('metadata/tokenft/tokenizer_config.json',\n",
       " 'metadata/tokenft/special_tokens_map.json',\n",
       " 'metadata/tokenft/tokenizer.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.save_pretrained(\"metadata/fine_tuned\")\n",
    "trainer.tokenizer.save_pretrained(\"metadata/tokenft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c6a8c54-8468-4af9-be3a-af8128faf27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorboard import notebook\n",
    "# log_dir = \"results/runs\"\n",
    "# notebook.start(\"--logdir {} --port 4000\".format(log_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3edc11a1-1746-438b-b93e-1cd67b0fb306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 01:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3755254745483398, 'eval_runtime': 69.7525, 'eval_samples_per_second': 2.867, 'eval_steps_per_second': 0.358, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4d9d288-4cb0-48de-8d6b-a53c28e69bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model_path = \"metadata/fine_tuned\"\n",
    "fine_tuned_tokenizer_path = \"metadata/tokenft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89057bef-224e-41f2-b441-4263a153a80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f1a45f66f14381ad7911811ab63457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    fine_tuned_model_path,\n",
    "    device_map={\"\": 0},\n",
    "    use_auth_token='auth_token'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9328887-5086-444a-be84-2040fd53b9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(fine_tuned_tokenizer_path, trust_remote_code=True,token=\"auth_token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51036bb5-d2e6-4440-847b-d8fb1d972bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"preprocessed_data.json\",\"r\") as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f79de0b6-811b-4856-a0a0-4a2dc8bb610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ph = data['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9213592-0949-4bb3-8bfc-33d0b363873a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>[INST]<<SYS>>You are a resourceful medical assistant. Please ensure your answers are unbiased. Make sure the answers are from the text provided.<</SYS>>Patient Note: 17 yo male with no PMH presents with 3-4 months of palpitations\\r\\n-episodes occur randomly, no associated with activity, associated with shortness of breath and pre-syncope\\r\\n-no sweating, feeling of impending doom, anxiety with episodes, no diarrhea\\r\\n-takes adderall a few times that is prescribed to friend, however has been taking this for a year now\\r\\n-no history of thyroid problems\\r\\nPMH: none\\r\\nMeds: adderall (not prescribed)\\r\\nFamHx: Mom- \"thyroid problem\"; dad- heart attack at 52\\r\\nSocial: lives with roomate; 3-4 alcoholic beverages/week, no durgs, sexually active w girlfriend and uses condoms.\\nExtract phrases from this text which may help understand the patient\\'s medical condition.[/INST]dad- heart attack, Mom- \"thyroid problem, episodes, adderall, adderall, shortness of breath, palpitations, 3-4 months of, 17 yo, male</s>'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset['Prompt'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c421f98-9462-4081-8f6e-060fa1c57009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST]<<SYS>>You are a resourceful medical assistant. Please ensure your answers are unbiased. Make sure the answers are from the text provided.<</SYS>>Patient Note: 17 yo male with no PMH presents with 3-4 months of palpitations\n",
      "-episodes occur randomly, no associated with activity, associated with shortness of breath and pre-syncope\n",
      "-no sweating, feeling of impending doom, anxiety with episodes, no diarrhea\n",
      "-takes adderall a few times that is prescribed to friend, however has been taking this for a year now\n",
      "-no history of thyroid problems\n",
      "PMH: none\n",
      "Meds: adderall (not prescribed)\n",
      "FamHx: Mom- \"thyroid problem\"; dad- heart attack at 52\n",
      "Social: lives with roomate; 3-4 alcoholic beverages/week, no durgs, sexually active w girlfriend and uses condoms.\n",
      "Extract phrases from this text which may help understand the patient's medical condition.[/INST]Mom- \"thyroid problem\", palpitations, no diarrhea, adderall, 17 yo, male, shortness of breath, pre-syncope, 3-4 months, 3-4 months, 3-4 months, 3-4 months, no sweating, no anxiety, no anxiety, no anxiety, no thyroid problems, no thyroid problems, no thyroid problems, no thyroid problems, no thyroid problems, no thyroid problems, no thyroid problems, no thyroid problems, no thyroid problems, no thyroid problems, no thyroid problems, no thyroid problems, no thyroid problems, no thyroid problems, no thyroid problems, no thyroid problems, no thyroid problems, no thyroid problems, no thyroid problems, no thyroid problems, no thyroid problems,\n"
     ]
    }
   ],
   "source": [
    "idx = eval_dataset[\"Prompt\"][1].index(\"[/INST]\") + 7\n",
    "\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer,max_length=435, truncation = True)\n",
    "\n",
    "result = pipe(eval_dataset[\"Prompt\"][1][:idx])\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1da568-c309-4c72-9a12-65e1f855dfeb",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b083237-cdca-4235-a17c-940dc3a4799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f89352be-db99-4e0f-8696-664f5b6639e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(patient_note, model_name, tokenizer_version):\n",
    "    system_prompt = system_prompt = \"You are a resourceful medical assistant. Please ensure your answers are unbiased. Make sure the answers are from the text provided\"\n",
    "    pipe = pipeline(task=\"text-generation\",model = model_name, tokenizer = tokenizer_version,max_length=600)\n",
    "    result = pipe(f\"<s>[INST]<<SYS>>{system_prompt}<<SYS>>{patient_note} [/INST]\")\n",
    "    \n",
    "    # process the keywords\n",
    "    s1 = result[0]['generated_text'].split(\"[/INST]\")\n",
    "    lst = s1[1].split(',')\n",
    "    a  = set()\n",
    "    for x in lst: a.add(x)\n",
    "    return {\n",
    "        'response':s1,\n",
    "        'keywords': a\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52bf63ab-8acb-4a84-8acb-6b21f83d748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = []\n",
    "for i in range((eval_dataset.shape[0])):\n",
    "    user_prompt = eval_dataset['Prompt'][i].split('[/INST]')[0].split('<</SYS>>')[1]\n",
    "    result = generate(user_prompt,model,tokenizer)\n",
    "    predicted_keywords = list(result['keywords'])\n",
    "    predicted.append(predicted_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69ea43f6-288e-462f-9651-f5061ab2e6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth =  [ x.split('[/INST]')[1] for x in eval_dataset['Prompt'] ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fb2b864-d806-4eff-a084-c98f6d716759",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for x in ground_truth:\n",
    "    lst.append(x.replace(\"</s>\",\"\").split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "371ff1f1-4b25-483f-9787-06e1bbc1b5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "def file_to_csv(lst,filename):\n",
    "    # Open the file in write mode\n",
    "    with open(filename, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # Write the data to the CSV file\n",
    "        writer.writerows(lst)\n",
    "\n",
    "    print(\"Data saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2f97d44-3afb-4b07-97e1-d858ede8374d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to Ground_truth.csv\n",
      "Data saved to Predicted.csv\n"
     ]
    }
   ],
   "source": [
    "file_to_csv(lst,\"Ground_truth.csv\")\n",
    "file_to_csv(predicted,\"Predicted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9df9ade-ab88-4da0-9fda-b4185dc6995d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
